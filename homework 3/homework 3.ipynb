{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1fd2cf-2183-4aac-bf0d-fc36e3ea2e96",
   "metadata": {},
   "source": [
    "# Problem 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f3ecdb-b4ec-411e-83b7-62981d5729da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "# setup\n",
    "fp = \"data/VOCdevkit/VOC2012/Annotations/2007_000027.xml\"\n",
    "\n",
    "def parse_file(fp):    \n",
    "    # extract xml tree\n",
    "    tree = ET.parse(fp)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # identify objects\n",
    "    # extract boundary box data\n",
    "    output = []\n",
    "    for obj in root.findall(\"./object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        box = obj.find(\"bndbox\")\n",
    "        x = int(box.find(\"xmin\").text)\n",
    "        xmax = int(box.find(\"xmax\").text)\n",
    "        y = int(box.find(\"ymin\").text)\n",
    "        ymax = int(box.find(\"ymax\").text)\n",
    "        \n",
    "        w = xmax - x\n",
    "        h = ymax - y\n",
    "        \n",
    "        coords = [name, x, y, w, h]\n",
    "        output.append(coords)\n",
    "\n",
    "    # put in numpy array format \n",
    "    output = np.array(output)\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b7d6a-1de0-4afa-880f-c6397e6a0976",
   "metadata": {},
   "source": [
    "# Problem 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4e08f6-1982-4daf-8e42-5ea1839b45c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "\n",
    "xml_path = \"data/VOCdevkit/VOC2012/Annotations/2007_000027.xml\"\n",
    "img_path = \"data/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\"\n",
    "\n",
    "def show_image(img_path, xml_path):\n",
    "    # load image\n",
    "    # load xml file\n",
    "    img = Image.open(img_path)\n",
    "    bndbox = parse_file(xml_path)\n",
    "    \n",
    "    # make figure\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # make boxes\n",
    "    for obj in bndbox:\n",
    "        box = patches.Rectangle((int(obj[1]), int(obj[2])), int(obj[3]), int(obj[4]), \n",
    "                                linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496df472-c4be-439a-881b-9eca1699ae5a",
   "metadata": {},
   "source": [
    "# Problem 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d51f9-188f-449f-8a83-778df5b9ee31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41a336b6-d028-4577-8c0c-53104ce26420",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407de7a-090a-4891-a110-0bb84fe13953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagecorruptions import corrupt, get_corruption_names\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from time import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "# setup\n",
    "corr_names = get_corruption_names()\n",
    "folder_path = \"data/VOCdevkit/VOC2012/JPEGImages/\"\n",
    "\n",
    "img_paths = [os.path.join(folder_path, img_path) for img_path in os.listdir(folder_path)]\n",
    "random.shuffle(img_paths)\n",
    "partition = int(0.8 * len(img_paths))\n",
    "train_paths = img_paths[:partition]\n",
    "val_paths = img_paths[partition:]\n",
    "\n",
    "# generate corrupted datasets\n",
    "def corrupt_set(img_paths):\n",
    "    start = time()\n",
    "    imgs_final = []\n",
    "    for img_path in img_paths:\n",
    "        # load image\n",
    "        # resize image\n",
    "        img = np.array(Image.open(img_path))\n",
    "        img = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # generate corruptions\n",
    "        # add to larger dataset\n",
    "        #for corr_name in corr_names:\n",
    "        for sev in range(1,6):\n",
    "            img_noised = corrupt(img, corruption_name=\"gaussian_noise\", severity=sev)\n",
    "            img_pair = np.stack([img_noised, img], axis=3)\n",
    "            imgs_final.append(img_pair)\n",
    "    print(time() - start)\n",
    "    return(imgs_final)\n",
    "\n",
    "# train_final = corrupt_set(train_paths)\n",
    "# val_final = corrupt_set(val_paths)\n",
    "\n",
    "# save dataset\n",
    "# np.save(\"train_imgs.npy\", train_final)\n",
    "# np.save(\"val_imgs.npy\", val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaeaf669-bdc4-41d2-8005-b0aafc4b672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image data class\n",
    "\n",
    "class ImgData:\n",
    "    def __init__(self, fp):\n",
    "        # load dataset\n",
    "        # reshape dataset\n",
    "        data = np.load(fp).transpose(0,3,1,2,4)\n",
    "        \n",
    "        # split into corrupted, original images\n",
    "        # convert to pytorch tensors\n",
    "        self.corrupted = torch.from_numpy(data[:,:,:,:,0]).to(torch.float32)\n",
    "        self.orig = torch.from_numpy(data[:,:,:,:,1]).to(torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corrupted)\n",
    "\n",
    "    def __getitem__(self, rownum):\n",
    "        corrupted = self.corrupted[rownum, :, :, :]\n",
    "        orig = self.orig[rownum, :, :, :]\n",
    "        return corrupted, orig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7766049-66e6-4134-a9e3-dc97cd83830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoencoder model class\n",
    "\n",
    "class CorruptioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CorruptioNet, self).__init__()\n",
    "        \n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 8, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 32, 2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 2, stride=2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ad4fbf9-14c9-4c6a-b890-fb2a4e49c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training function\n",
    "\n",
    "def train_model(model, data, epochs):\n",
    "    start = time()\n",
    "    \n",
    "    # define loss function\n",
    "    # set optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    # set up data loader\n",
    "    train_loader = torch.utils.data.DataLoader(data, shuffle=True, batch_size=32)\n",
    "    \n",
    "    # run training loop\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, (corrupted, orig) in enumerate(train_loader):\n",
    "            print(f\"\"\"Epoch {epoch}, batch {batch_id}/{len(train_loader)}\"\"\", end=\"\\r\")\n",
    "            optimizer.zero_grad()\n",
    "            out_image = model(corrupted)\n",
    "            loss = criterion(orig, out_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append([epoch, batch_id, loss.item()])\n",
    "        \n",
    "    print(time() - start)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664adfec-ffcf-4fe0-85a4-32b6decd3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = ImgData(\"train_imgs.npy\")\n",
    "val = ImgData(\"val_imgs.npy\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=32)\n",
    "val_loader = torch.utils.data.DataLoader(val, shuffle=True, batch_size=len(val))\n",
    "\n",
    "# train model\n",
    "trained_model, losses = train_model(model, train_loader, 1)\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25439ef-a0ef-44bf-aa82-48c9bfc89b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = CorruptioNet()\n",
    "model.load_state_dict(torch.load('model_state.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac091d8-7702-48e9-85bc-62b4f978c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 33/536\r"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = CorruptioNet()\n",
    "val_loader = torch.utils.data.DataLoader(val, shuffle=True, batch_size=32)\n",
    "trained_model, losses = train_model(model, val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d676f7ee-6ec8-4d78-af22-573708cf44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"data/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\"\n",
    "img = Image.open(img_path)\n",
    "corr_name = \"gaussian_noise\"\n",
    "sev = 5\n",
    "img_noised = corrupt(np.array(img), corruption_name=corr_name, severity=sev)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(10,5))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_noised)\n",
    "ax[2].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7ef3bfb-14cc-4b3a-91f1-926b9ead15a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d23cdd9-24e6-469c-8c89-c402f4850040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 535, 8949084.596679688]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b14f2-36fa-4467-979e-351698f7d934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
