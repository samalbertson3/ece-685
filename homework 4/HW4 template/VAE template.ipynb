{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The material presented in this jupyter notebook is part of the \"ECE 685D: Introduction to Deep Learning\" course offered at Duke University.\n",
    "\n",
    "# Session: Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8b: Variational Autoencoders (VAEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"VAE.jpg\" width=400 height=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "A VAE uses two neural networks,\n",
    "\n",
    "* Encoder ($q_{\\phi}(z|x)$): Encodes X into Z. To get Z, we do the following\n",
    "    * Encoder outputs $\\mu$ and log-variance (instead of $\\sigma$).\n",
    "    * Sample $z \\sim Normal(\\mu, \\sigma^2)$ using reparameterization trick.\n",
    "    \n",
    "* Decoder ($p_{\\theta}(x|z)$): Decode from Z to X.\n",
    "\n",
    "To train a VAE, we maximize the Evidence Lower Bound (ELBO):\n",
    "\n",
    "$$ELBO (x) = \\mathbb{E}_{q_{\\phi}(z|x)}\\log(p_{\\theta}(x|z)) - \\text{KL}[q_{\\phi}(z|x) || p(z)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_set,test_set,train_loader,test_loader = {},{},{},{}\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "train_set['mnist'] = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "test_set['mnist'] = torchvision.datasets.MNIST(root='../data', train=False, download=True, transform=transform)\n",
    "train_loader['mnist'] = torch.utils.data.DataLoader(train_set['mnist'], batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader['mnist'] = torch.utils.data.DataLoader(test_set['mnist'], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc21 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc22 = nn.Linear(n_hid, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, n_hid)\n",
    "        self.fc4 = nn.Linear(n_hid, n_in)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encoder forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Input image\n",
    "            \n",
    "        Returns:\n",
    "            mu: self.fc21(h1)\n",
    "            logvar: self.fc22(h1)\n",
    "        \"\"\"\n",
    "        \n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Implements: z = mu + epsilon*stdev.\n",
    "            \n",
    "        Args: \n",
    "            mu: mean\n",
    "            logvar: log of variance\n",
    "        \n",
    "        Return:\n",
    "            z: sample from Normal(mu, var).\n",
    "            \n",
    "            Epsilon is sampled from standard normal distribution. \n",
    "            \\epsilon \\sim Normal(0, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        stdev = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(stdev)\n",
    "        return mu + eps*stdev\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Decoder forward pass.\n",
    "        \n",
    "        Args:\n",
    "            z: Batch of latent representations.\n",
    "        \n",
    "        Returns: \n",
    "            x_recon: Image probabilities.\n",
    "        \"\"\"\n",
    "        \n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Implements forward pass of VAE.\n",
    "        \n",
    "        Args:\n",
    "            x: Batch of input images.\n",
    "        \n",
    "        Returns:\n",
    "            x_recon: Batch of reconstructed images.\n",
    "            mu: Batch of mean vectors\n",
    "            logvar: Batch of log-variance vectors\n",
    "        \"\"\"\n",
    "        \n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"Computes the loss = -ELBO = Negative Log-Likelihood + KL Divergence.\n",
    "    \n",
    "    Args: \n",
    "        recon_x: Decoder output.\n",
    "        x: Ground truth.\n",
    "        mu: Mean of Z\n",
    "        logvar: Log-Variance of Z\n",
    "        \n",
    "        p(z) here is the standard normal distribution with mean 0 and identity covariance.\n",
    "    \"\"\"\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') # BCE = -Negative Log-likelihood\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL Divergence b/w q_\\phi(z|x) || p(z)\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0),-1)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, mu, logvar = model(data)\n",
    "        loss = loss_function(output, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % (len(train_loader)//2) == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), train_loss/(batch_idx+1)))\n",
    "    return train_loss\n",
    "\n",
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.view(data.size(0),-1)\n",
    "            data = data.to(device)\n",
    "            output, mu, logvar = model(data)\n",
    "            loss = loss_function(output, data, mu, logvar)\n",
    "            test_loss += loss.item() # sum up batch loss\n",
    "    test_loss = (test_loss*batch_size)/len(test_loader.dataset)\n",
    "    print('Test({}): Loss: {:.4f}'.format(\n",
    "        epoch, test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer_name, model, **kwargs):\n",
    "    if optimizer_name=='Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),lr=kwargs['lr'])\n",
    "    elif optimizer_name=='SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError('Not valid optimizer name')\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "data_name = 'mnist'\n",
    "optimizer_name = 'Adam'\n",
    "\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "n_in = 28*28\n",
    "n_hid = 400\n",
    "z_dim = 20\n",
    "\n",
    "device = torch.device(device)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(n_in, n_hid, z_dim).to(device)\n",
    "\n",
    "optimizer = make_optimizer(optimizer_name, vae, lr=lr)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(vae, device, train_loader[data_name], optimizer, epoch)\n",
    "\n",
    "test(vae, device, test_loader[data_name], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img1, img2):\n",
    "    npimg1 = img1.cpu().numpy()\n",
    "    npimg2 = img2.cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(20,10))\n",
    "    axes[0].imshow(np.transpose(npimg1, (1,2,0)), interpolation='nearest')\n",
    "    axes[1].imshow(np.transpose(npimg2, (1,2,0)), interpolation='nearest')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,_ = next(iter(test_loader[data_name]))\n",
    "data = data[:32]\n",
    "data_size = data.size()\n",
    "data = data.view(data.size(0),-1).to(device)\n",
    "output, _, _ = vae(data)\n",
    "output = output.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(data.reshape(data_size), padding=0), make_grid(output.reshape(data_size), padding=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(iter(test_loader[data_name]))\n",
    "X_batch, Y_batch = X_test[:128], Y_test[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = X_test.size()\n",
    "data = X_test.view(X_test.size(0),-1).to(device)\n",
    "Z, _ = vae.encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(x):\n",
    "    \"\"\"Computes the centroid of images in the latent space.\n",
    "    \n",
    "    Args:\n",
    "        x: torcch.Tensor of shape: batch x 1 x 28 x 28\n",
    "        \n",
    "    Returns:\n",
    "        z_centroid: Centroid in latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_size = x.size()\n",
    "    data = x.view(x.size(0),-1).to(device)\n",
    "    Z, _ = vae.encode(data)\n",
    "    Z_centroid = Z.mean(axis=0)   \n",
    "\n",
    "    return Z_centroid\n",
    "\n",
    "def get_a2b(a_label: int, b_label: int):\n",
    "    \"\"\"Computes the vector in latent space from centroid of a to centroid of b.\n",
    "        \n",
    "    Args:\n",
    "        a_label: Class `a`\n",
    "        b_label: Class `b`\n",
    "    \n",
    "    Returns:\n",
    "        z_a2b: Vector from centroid of `a` to centroid of `b`.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_a = X_test[Y_test == a_label]\n",
    "    x_b = X_test[Y_test == b_label]\n",
    "\n",
    "    z_a = get_centroid(x_a)\n",
    "    z_b = get_centroid(x_b)\n",
    "    z_a2b = z_b - z_a\n",
    "    return z_a2b\n",
    "\n",
    "def interpolate(a_label = 0):    \n",
    "    \"\"\"Interpolate in latent space from one class to another class.\"\"\"\n",
    "    \n",
    "    all_classes = np.arange(0, 10)\n",
    "    all_classes = np.delete(all_classes, a_label)\n",
    "    z_a2b_all = []\n",
    "    for b_label in all_classes:\n",
    "        z_a2b_all.append(get_a2b(a_label, b_label))\n",
    "    \n",
    "    x_a = X_test[Y_test == a_label]\n",
    "    data_size = x_a.size()\n",
    "    data = x_a.view(x_a.size(0),-1).to(device)\n",
    "    z_a, _ = vae.encode(data)\n",
    "    z_in = z_a[0]\n",
    "    \n",
    "    x_interpolated = []\n",
    "    for z_a2b in z_a2b_all:\n",
    "        for alpha in np.arange(0, 2, 0.2):\n",
    "            z = z_in + alpha*z_a2b\n",
    "            x_vae = vae.decode(z).detach()\n",
    "            x_interpolated.append(x_vae)\n",
    "    \n",
    "    nrow = len(x_interpolated)\n",
    "    x_all = torch.stack(x_interpolated)\n",
    "    img = make_grid(x_all.reshape((nrow, 1, 28, 28)), padding=0, nrow=nrow//9)\n",
    "    npimg = img.cpu().numpy()\n",
    "    \n",
    "    return npimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "\n",
    "for a_label, ax in enumerate(axes.flat):\n",
    "    img = interpolate(a_label=a_label)\n",
    "    ax.imshow(np.transpose(img, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
