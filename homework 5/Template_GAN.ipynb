{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# Generate images with condition labels\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 30\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "\n",
    "1. If you are trying to debug the model, train the model for 1 epoch and visualize the generator and discriminator loss.\n",
    "2. First try to train the GAN on a smaller dataset (use digits 0 and 1), if the result looks resonable then train the model on the entire dataset.\n",
    "\n",
    "Note: A single epoch of training should take 30-45 seconds for 1 epoch on GPU when bath_size=200. While tuning the `batch_size` and `epochs` may lead to better results, we do not expect you to tune these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Put your code here\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return batch of images.\"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "        return\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return the logits.\"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "        \n",
    "        return\n",
    "\n",
    "class DCGAN(object):\n",
    "    \n",
    "    def __init__(self, epochs, batch_size):\n",
    "        \n",
    "        ##### ---- YOUR CODE HERE ---- #####\n",
    "        self.G = \n",
    "        self.D = \n",
    "        self.loss = \n",
    "        ##### ----                ---- #####\n",
    "\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.number_of_images = 10\n",
    "        \n",
    "    def train(self, train_loader):\n",
    "        \n",
    "        disc_loss = []\n",
    "        genr_loss = []\n",
    "        \n",
    "        generator_iter = 0\n",
    "        \n",
    "        for epoch in trange(self.epochs):\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                \n",
    "                # Step 1: Train discriminator\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "                \n",
    "                real_labels = torch.ones(self.batch_size)\n",
    "                fake_labels = torch.zeros(self.batch_size)\n",
    "\n",
    "                images, z = images.to(device), z.to(device)\n",
    "                real_labels, fake_labels = real_labels.to(device), fake_labels.to(device)\n",
    "\n",
    "                # Compute the BCE Loss using real images\n",
    "                real_logits = self.D(images)\n",
    "                real_logits = torch.squeeze(real_logits)\n",
    "                d_loss_real = self.loss(real_logits, real_labels)\n",
    "\n",
    "                # Compute the BCE Loss using fake images\n",
    "                fake_images = self.G(z)\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                d_loss_fake = self.loss(fake_logits, fake_labels)\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                self.D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Step 2: Train Generator\n",
    "                z = torch.randn(self.batch_size, 100, 1, 1).to(device)\n",
    "                \n",
    "                fake_images = self.G(z)\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                g_loss = self.loss(fake_logits, real_labels)\n",
    "\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                generator_iter += 1\n",
    "\n",
    "                disc_loss.append(d_loss.item())\n",
    "                genr_loss.append(g_loss.item())\n",
    "\n",
    "        return disc_loss, genr_loss\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            generated_images.append(sample.reshape(28, 28))\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCGAN(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_loss, genr_loss = model.train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the generated images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100, 100, 1, 1).to(device)\n",
    "images = model.generate_img(z, 100)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = gridspec.GridSpec(10, 10)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        sample = images[i*10+j]\n",
    "        ax = plt.subplot(gs[i, j])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the discriminator and generator loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gan_losses(disc_loss, genr_loss):\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "    fig.add_subplot(121)\n",
    "    plt.title('Discriminator Loss', fontsize=16)\n",
    "    plt.xlabel('Iteration', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt1 = plt.plot(disc_loss)\n",
    "    fig.add_subplot(122)\n",
    "    plt.title('Generator Loss', fontsize=16)\n",
    "    plt.xlabel('Iteration', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt2 = plt.plot(genr_loss)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_losses(disc_loss, genr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
