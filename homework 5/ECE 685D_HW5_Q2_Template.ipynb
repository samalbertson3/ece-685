{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-xeTyPIWqvg"
   },
   "source": [
    "# Problem 2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhGmvDasWqvh"
   },
   "source": [
    "## Note\n",
    "- We will install NLTK to get the Gutenberg Corpus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKzP21cMWqvi"
   },
   "outputs": [],
   "source": [
    "# Download nltk modules.\n",
    "!pip install nltk bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b88Rrrm9Wqvi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata, copy\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "#download corpus\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5nXpF6OWqvi"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRiCrd3SWqvi"
   },
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "#Removing all the noise\n",
    "def denoise_text(text):\n",
    "    #remove html strips\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    #remove \\n\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    #remove square brackets\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    #replace punctuation with space\n",
    "    text = re.sub(r'[,.;@#?!&$\\-]+\\ *', ' ', text, flags=re.VERBOSE)\n",
    "    #remove special characters\n",
    "    text=re.sub(r'[^a-zA-z0-9\\s]', '', text)\n",
    "    #remove extra spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "corpus = denoise_text(corpus)\n",
    "words = corpus.split(' ')\n",
    "unique_words = np.unique(words)\n",
    "vocab_size = len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add your code to generate 6-gram dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and pad the dataset to make its feature size 100.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TAxo5OIWqvj",
    "outputId": "fa9eeb90-29ba-4e6f-8498-5c2d09f1f461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17168\n"
     ]
    }
   ],
   "source": [
    "# Convert your dataset to tensors\n",
    "train_data = TensorDataset(torch.from_numpy(X), torch.from_numpy(y.astype('int')))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input features: \\n', sample_x)\n",
    "print('Sample input labels: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMAx8R_fWqvj"
   },
   "source": [
    "## Write the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CFgce5aWqvk"
   },
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self,n_layers,vocab_size,hidden_dim,embedding_dim):\n",
    "        super(LSTMGenerator,self).__init__()\n",
    "        self.output_dim = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        \"\"\"Initializes the constructor and defines the model parameters.\"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        ############ ---- YOUR CODE HERE ---- ############\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "\n",
    "\n",
    "    def forward(self,x,hidden):\n",
    "        \"\"\"Computes the model forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: The input text sequence with shape [seq_len, batch_size].\n",
    "        \n",
    "        Returns:\n",
    "            logit: Expected shape is [batch_size, vocab_size].\n",
    "        \"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        ############ ---- YOUR CODE HERE ---- ############\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        h0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWdyq5m_Wqvk"
   },
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer_name, model, **kwargs):\n",
    "    if optimizer_name=='Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=kwargs['lr'])\n",
    "    elif optimizer_name=='SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError('Not valid optimizer name')\n",
    "    return optimizer\n",
    "    \n",
    "def make_scheduler(scheduler_name, optimizer, **kwargs):\n",
    "    if scheduler_name=='MultiStepLR':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=kwargs['milestones'],gamma=kwargs['factor'])\n",
    "    else:\n",
    "        raise ValueError('Not valid scheduler name')\n",
    "    return scheduler\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, epoch):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.text).squeeze(1)\n",
    "        loss = criterion(output, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % (len(iterator)//2) == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(iterator), train_loss/(batch_idx+1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwY0lLCZWqvk"
   },
   "source": [
    "### Set your model parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-ZrwJYhWqvk"
   },
   "outputs": [],
   "source": [
    "##### ---- YOUR CODE HERE ---- #####\n",
    "\n",
    "# Step 1: Define model hyperparameters.\n",
    "embedding_dim =\n",
    "hidden_dim =\n",
    "out_dim = \n",
    "num_layers = \n",
    "num_epochs = \n",
    "\n",
    "\n",
    "# Step 2: Initialize the LSTM model.\n",
    "model_lstm = \n",
    "\n",
    "# Step 3: Set optimizer params for the utility functions (See usage below).\n",
    "learning_rate = 0.001\n",
    "optimizer_name = 'Adam'\n",
    "scheduler_name = 'MultiStepLR'\n",
    "##### ----                ---- #####\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = make_optimizer(optimizer_name, model, lr=learning_rate, momentum=0, weight_decay=0)\n",
    "scheduler = make_scheduler(scheduler_name, optimizer, milestones=[5], factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHBt65eHWqvl"
   },
   "source": [
    "### __Run this block to get results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb_Ls2UjWqvl"
   },
   "outputs": [],
   "source": [
    "print('Start training...')\n",
    "for epoch in trange(1, num_epochs + 1):\n",
    "    train(model_lstm, train_loader, optimizer, criterion, epoch)\n",
    "    scheduler.step()\n",
    "    print('Optimizer Learning rate: {0:.4f}'.format(optimizer.param_groups[0]['lr']))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report your final loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Generate a 100 word sentence from your trained model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(model, text, text_len = 100):\n",
    "    model.eval()\n",
    "    state_hidden = model.init_hidden(len(text.split(' ')))\n",
    "    sentence = text.split(' ')\n",
    "    for i in range(text_len - len(text.split(' '))):\n",
    "        #your code here\n",
    "        new_word = None\n",
    "\n",
    "\n",
    "        sentence.append(new_word)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "text = 'his natural shyness was overcome'\n",
    "\n",
    "sentence = predict_text(model, text)\n",
    "\n",
    "print(' '.join(sentence))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9afbedeb8f918e0257feae8dffcd58de91e672fc6d361ae6590127510cf6ca50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
