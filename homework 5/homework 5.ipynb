{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131ae3ab-1d96-4dc7-a565-6fbd1a28be07",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a1beaf-580d-4c00-8676-9abb8e7915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# Generate images with condition labels\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe00a1d-502f-48e0-be2b-4fd7b1d10ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 1\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e9cf29-eb27-4562-8b4c-d4fbfded6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Put your code here\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58dab0b-2b27-4982-8b2e-47f55064031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratioNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(GeneratioNet, self).__init__()\n",
    "        \n",
    "        self.Decoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 256, 2, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 1, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return batch of images.\"\"\"\n",
    "        \n",
    "        x = x.view(batch_size, 1, 10, 10)\n",
    "        x = self.Decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5e06e5-1822-408d-8382-26c7221a9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscrimiNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DiscrimiNet, self).__init__()\n",
    "\n",
    "        self.Encoder = nn.Sequential(\n",
    "                nn.Conv2d(1, 64, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(0.5),\n",
    "            \n",
    "                nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(0.5),\n",
    "            \n",
    "                nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "            \n",
    "                nn.Conv2d(256, 512, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "            )\n",
    "        \n",
    "        self.Regression = nn.Linear(512*4*4, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return the logits.\"\"\"\n",
    "        \n",
    "        x = self.Encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.Regression(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf37d64-b9ad-4eea-a1ba-2f26a92ae2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANet(object):\n",
    "    \n",
    "    def __init__(self, epochs, batch_size):\n",
    "        \n",
    "        ##### ---- YOUR CODE HERE ---- #####\n",
    "        self.G = GeneratioNet()\n",
    "        self.D = DiscrimiNet()\n",
    "        self.loss = nn.MSELoss()\n",
    "        ##### ----                ---- #####\n",
    "\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.number_of_images = 10\n",
    "        \n",
    "    def train(self, train_loader):\n",
    "        \n",
    "        disc_loss = []\n",
    "        genr_loss = []\n",
    "        \n",
    "        generator_iter = 0\n",
    "        \n",
    "        for epoch in trange(self.epochs):\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                print(f\"Epoch {epoch+1}: Batch {i+1} of {len(train_loader)}\")\n",
    "                \n",
    "                # Step 1: Train discriminator\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "                \n",
    "                real_labels = torch.ones(self.batch_size)\n",
    "                fake_labels = torch.zeros(self.batch_size)\n",
    "\n",
    "                images, z = images.to(device), z.to(device)\n",
    "                real_labels, fake_labels = real_labels.to(device), fake_labels.to(device)\n",
    "\n",
    "                # Compute the BCE Loss using real images\n",
    "                real_logits = self.D(images)\n",
    "                real_logits = torch.squeeze(real_logits)\n",
    "                d_loss_real = self.loss(real_logits, real_labels)\n",
    "\n",
    "                # Compute the BCE Loss using fake images\n",
    "                print(\"Generating images...\")\n",
    "                fake_images = self.G(z)\n",
    "                print(\"Discriminating images...\")\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                d_loss_fake = self.loss(fake_logits, fake_labels)\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                self.D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Step 2: Train Generator\n",
    "                z = torch.randn(self.batch_size, 100, 1, 1).to(device)\n",
    "                \n",
    "                fake_images = self.G(z)\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                g_loss = self.loss(fake_logits, real_labels)\n",
    "\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                generator_iter += 1\n",
    "\n",
    "                disc_loss.append(d_loss.item())\n",
    "                genr_loss.append(g_loss.item())\n",
    "\n",
    "        return disc_loss, genr_loss\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            generated_images.append(sample.reshape(28, 28))\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bea9f9-ab0d-44c1-87b6-b7f07b239682",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set number_of_images, z\n",
    "number_of_images = 1\n",
    "z = torch.randn(batch_size, 100)\n",
    "\n",
    "# set up model\n",
    "# run training\n",
    "model = DCGANet(epochs, batch_size)\n",
    "disc_loss, genr_loss = model.train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8186cd6-6852-4911-84dc-f23ee9cb72e1",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b248f1b5-e783-4943-8a05-448579f5616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata, copy\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = 'cpu'\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "#download corpus\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31cf840e-7fed-4794-be9f-c9dbb5a4da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all the noise\n",
    "def denoise_text(text):\n",
    "    #remove html strips\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    #remove \\n\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    #remove square brackets\n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    #replace punctuation with space\n",
    "    text = re.sub(r'[,.;@#?!&$\\-]+\\ *', ' ', text, flags=re.VERBOSE)\n",
    "    #remove special characters\n",
    "    text=re.sub(r'[^a-zA-z0-9\\s]', '', text)\n",
    "    #remove extra spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb363481-b3ee-4bf7-8287-b8191b503b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "corpus_raw = nltk.corpus.gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "# clean dataset\n",
    "corpus_raw = denoise_text(corpus_raw)\n",
    "words = corpus_raw.split(' ')\n",
    "\n",
    "# tokenize\n",
    "corpus_t = nltk.word_tokenize(corpus_raw)\n",
    "\n",
    "# convert to one-hot encoding\n",
    "unique_words = np.unique(corpus_t)\n",
    "d = {word: i for i, word in enumerate(unique_words)}\n",
    "corpus_n = torch.Tensor([d[word] for word in corpus_t])\n",
    "corpus = F.one_hot(corpus_n.to(torch.int64))\n",
    "\n",
    "# generate 6-grams\n",
    "# split into 5-grams and targets\n",
    "grams_pre = torch.stack(\n",
    "    [corpus[i:i+6,:] for i in range(len(corpus)-6+1)], \n",
    "    dim=-1).permute(2,0,1)\n",
    "grams = grams_pre[:,:5,:]\n",
    "targets = grams_pre[:,5,:]\n",
    "\n",
    "# pad dataset to N=100\n",
    "#grams = torch.cat((grams,\n",
    "#                     torch.zeros(len(grams), 95, len(unique_words)),\n",
    "#                     dim=1)\n",
    "# too big ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4b8f245-298f-41cb-be5c-c80f475f9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data loader\n",
    "\n",
    "gram_set = TensorDataset(grams, targets)\n",
    "dl = DataLoader(gram_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b7e0803-ee0d-40a3-8236-5532cabc816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, n_classes, n_layers):\n",
    "        super(LSTMGenerator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size = self.in_dim, \n",
    "                                  hidden_size = self.h_dim, \n",
    "                                  num_layers = self.n_layers, \n",
    "                                  batch_first=True)\n",
    "        self.classifier = nn.Linear(in_features=self.h_dim, \n",
    "                                    out_features=self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initialize H and C\n",
    "        h0 = torch.zeros((self.n_layers, len(x), self.h_dim), dtype=x.dtype).to(device)\n",
    "        c0 = torch.zeros((self.n_layers, len(x), self.h_dim), dtype=x.dtype).to(device)\n",
    "        \n",
    "        m, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        logits = self.classifier(m[:, -1, :])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83b5c0e2-e6fb-497e-8ab6-b5f5e7df130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (grams, targets) = next(enumerate(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9a6b3f5c-0204-4e2a-82ec-274bb2617a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = len(unique_words)\n",
    "h_dim = 1000\n",
    "n_classes = len(unique_words)\n",
    "n_layers = 1\n",
    "grams = grams.long()\n",
    "\n",
    "out = LSTMGenerator(in_dim, h_dim, n_classes, n_layers)\n",
    "out2 = out(grams.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399805e9-835f-41c8-8620-4b542b77b15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "5aa59d7d-fa4a-4311-9d4d-2b682d19115a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
